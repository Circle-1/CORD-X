{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"884324ea-65fb-4b7b-91e3-40f438c2466b","_cell_guid":"b032efed-b298-4160-a75d-fbe5daa5e9fd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-10T09:46:12.390659Z","iopub.execute_input":"2021-10-10T09:46:12.391176Z","iopub.status.idle":"2021-10-10T09:46:12.482816Z","shell.execute_reply.started":"2021-10-10T09:46:12.391084Z","shell.execute_reply":"2021-10-10T09:46:12.482153Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing and Analysis\n// Work from this part!","metadata":{"_uuid":"a5668172-2e7e-40bb-8ac4-30f42ee60b51","_cell_guid":"3612c4fa-b465-4c23-a974-446bc0736fb2","trusted":true}},{"cell_type":"code","source":"# For data preprocessing and analysis part","metadata":{"_uuid":"a822188f-6190-499f-9b42-5d71053004dc","_cell_guid":"1d90666a-d789-468e-9bf4-71fc7a99677a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training part","metadata":{"_uuid":"2ad959a8-6384-4848-8d96-4948a57fed42","_cell_guid":"36869da4-77eb-4369-abe6-f819e6d40043","trusted":true}},{"cell_type":"code","source":"# For creating model and training\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Conv1D, LSTM, Dense, Dropout, Bidirectional, TimeDistributed\nfrom keras.layers import MaxPooling1D, Flatten\n\nmodel = keras.Sequential()\n\n# Creating the Neural Network model here...\nmodel.add(TimeDistributed(Conv1D(64, kernel_size=1, activation='relu', input_shape=(None, 50, 1))))\nmodel.add(TimeDistributed(MaxPooling1D(2)))\nmodel.add(TimeDistributed(Conv1D(128, kernel_size=1, activation='relu')))\nmodel.add(TimeDistributed(MaxPooling1D(2)))\nmodel.add(TimeDistributed(Conv1D(256, kernel_size=1, activation='relu')))\nmodel.add(TimeDistributed(MaxPooling1D(2)))\nmodel.add(TimeDistributed(Conv1D(512, kernel_size=1, activation='relu')))\nmodel.add(TimeDistributed(MaxPooling1D(2)))\nmodel.add(TimeDistributed(Flatten()))\nmodel.add(Bidirectional(LSTM(200, return_sequences=True)))\nmodel.add(Dropout(0.25))\nmodel.add(Bidirectional(LSTM(200, return_sequences=True)))\nmodel.add(Dropout(0.25))\nmodel.compile(optimizer='adam', loss='mse')","metadata":{"_uuid":"20e2ff0e-44b2-4045-b5ca-e48c306f45da","_cell_guid":"06303da5-238a-4a7f-989a-eb43714e7986","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-10T09:46:15.510435Z","iopub.execute_input":"2021-10-10T09:46:15.510945Z","iopub.status.idle":"2021-10-10T09:46:19.881434Z","shell.execute_reply.started":"2021-10-10T09:46:15.510900Z","shell.execute_reply":"2021-10-10T09:46:19.880298Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# After the model has been constructed, we need to train\n# But first, let's construct the diagram\nfrom keras.utils.vis_utils import plot_model\nprint(model.summary())\nplot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:36:08.008616Z","iopub.execute_input":"2021-10-10T09:36:08.008957Z","iopub.status.idle":"2021-10-10T09:36:08.029202Z","shell.execute_reply.started":"2021-10-10T09:36:08.008874Z","shell.execute_reply":"2021-10-10T09:36:08.028204Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Testing part","metadata":{"_uuid":"afaebb0b-3f60-4e39-9045-e8790259033a","_cell_guid":"66fc1238-e654-4b6e-b4ed-f27c80d53ad3","trusted":true}},{"cell_type":"code","source":"# For testing model accuracy with real time data","metadata":{"_uuid":"e7168961-b5cb-4717-964c-12e398146db2","_cell_guid":"8fb9ea01-ff29-433e-ba9c-12ce74eebc37","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"3d468f98-c86c-42c3-9721-78351bf23914","_cell_guid":"97962311-23c5-42ea-8378-e7d18655c3b8","trusted":true}}]}